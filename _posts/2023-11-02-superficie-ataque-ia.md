---
layout: post
title: "La superficie de ataque de la Inteligencia Artificial"
date: "2023-11-02 15:00:00 +0000"
category: seguridad
tags:
- seguridad
- ia
- inteligencia artificial
- superficie
- ataques
imagefeature: 'https://live.staticflickr.com/65535/53304894335_b9265c0bef.jpg'
---
<a href="https://www.flickr.com/photos/fernand0/53304894335/" title="Detalle pasaje de madera de la torre"><img src="https://live.staticflickr.com/65535/53304894335_b9265c0bef_b.jpg" alt="Detalle pasaje de madera de la torre" class="img-responsive img-centered"></a>

Cuando introduces un nuevo sistema añades toda una panorámica de posibilidades donde un atacante puede intentar hacer algo. Cuantas más son las posibilidades, mayor es lo que llamamos la superficie de ataque.

En [The AI Attack Surface Map v1.0](https://danielmiessler.com/p/the-ai-attack-surface-map-v1-0/) Daniel Miessler nos da pistas sobre todos los sitios donde un atacante podría intentar obtener alguna ventaja cuando hablamos de la inteligencia artificial.

>  This resource is a first thrust at a framework for thinking about how to attack AI systems. 

Habla de los componentes (modelos, preguntas, índices, memoria, cadenas, agentes, ...) y luego habla de algunos ejemplos de ataques posibles (inyección de preguntas, *prompts*, ataques al entrenamiento, ...).

Interesante.
